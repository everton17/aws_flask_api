
# AWS EC2 Manage Instances API

Este projeto foi desenvolvido como objeto de estudos e aplica√ß√£o de uma s√©rie de conhecimentos, tecnologias e habilidades voltados para o ecossistema DevOps. Trabalhando alguns t√≥picos como: Program√ß√£o, Cloud, IaC, Containers e CI/CD.

O core do projeto se trata de uma aplica√ß√£o que possibilita intera√ß√µes simples com servi√ßo AWS EC2 via requisi√ß√µes HTTP, como por exemplo Listar instancias e realizar algumas a√ß√µes com as mesmas como: ligar, desligar, reiniciar e modificar a classe das instancias.


## üõ† Stack utilizada

**Aplica√ß√£o:** Python, Flask, Flask-Restful, Boto3, Gunicorn

**Infraestrutura:** AWS, Terraform, Docker, ECS (Elastic Container Service)

**CI/CD:** GitHub Actions 


## ‚úÖ API - Pr√© requisitos

Para utiliza√ß√£o da aplica√ß√£o precisaremos de alguns itens instados no nosso ambiente:

- Uma conta AWS, usu√°rio e credenciais com permiss√ß√µees ao servi√ßo EC2
- Python 3.10
- AWS Cli


## üîó Links

Segue abaixo alguns links que pode ajudar na configura√ß√£o do ambiente

[Instala√ß√£o do Python e AWS Cli no Windows](https://docs.aws.amazon.com/pt_br/elasticbeanstalk/latest/dg/eb-cli3-install-windows.html)

[Instala√ß√£o do Python e AWS Cli no Linux](https://docs.aws.amazon.com/pt_br/elasticbeanstalk/latest/dg/eb-cli3-install-linux.html)

[Criando um us√°rio AWS no console AWS](https://docs.aws.amazon.com/pt_br/IAM/latest/UserGuide/id_users_create.html#id_users_create_console)

[Configurando credenciais de usu√°rio no AWS Cli](https://docs.aws.amazon.com/pt_br/cli/latest/userguide/cli-configure-files.html)


## üè† Executando localmente

Ap√≥s a configura√ß√£o do ambiente e das credenciais de usu√°rio junto aos AWS Cli basta seguir os passos abaixo:

**Obs: Para usu√°rios windows recomendado utilizar o WSL2**

Clone o projeto

```bash
  git clone https://github.com/everton17/aws_flask_api.git
```

Entre no diret√≥rio do projeto

```bash
  cd aws_flask_api
```

Crie uma virtual-env

```bash
  python3 -m venv .venv
```

Ative a Virtual-env

```bash
  source .venv/bin/activate
```

Instale as bibliotecas do projeto

```bash
  pip install -r requirements.txt
```

Execute a aplica√ß√£o

```bash
  gunicorn --bind 0.0.0.0:5000 -w 4 run:app
```

## üê≥ Executando localmente com Docker

Ap√≥s a configura√ß√£o do ambiente e das credenciais de usu√°rio junto aos AWS Cli basta seguir os passos abaixo:

**Obs: para esta execu√ß√£o voc√™ necessariamente do docker intalado na sua maquina**

[Instala√ß√£o do Docker](https://docs.docker.com/get-docker/)


Clone o projeto

```bash
  git clone https://github.com/everton17/aws_flask_api.git
```

Entre no diret√≥rio do projeto

```bash
  cd aws_flask_api
```

Entre no diret√≥rio do projeto

```bash
  cd aws_flask_api
```

Execute o docker build referenciando as credenciais AWS como build-args

```bash
  docker build -t aws_ec2_flask_api . --build-arg ACCESS_KEY=<AWS_ACCESS_KEY> --build-arg SECRET_KEY=<AWS_SECRET_ACCESS_KEY>
```

Agora vamos executar o container da nossa aplica√ß√£o

```bash
  docker run -d --name aws-api -p 127.0.0.1:5000:5000 aws_ec2_flask_api:latest
```

## ‚òÅÔ∏è Executando na Cloud AWS

Para execu√ß√£o da nossa aplica√ß√£o na AWS o projeto contempla uma Stack Terraform, onde faremos o deploy atrav√©s de uma pipeline CI/CD utilizando o GitHub Actions

**Obs: para esta execu√ß√£o voc√™ precisar√° fazer um fork do projeto e algumas configura√ß√µes no seu GitHub e na sua conta AWS**

Para que possamos deployar nossa stack terraform na AWS precisaremos cumprir alguns pr√© requisitos:

**AWS**
-
- Criar um Bucket S3 para armazenar nosso Terraform Remote State
- Criar um novo usu√°rio na AWS com permiss√µes para criar e destruir recursos dos seguintes servi√ßos:
    - EC2
    - ECR
    - ECS
    - VPC
    - Cloud Watch Logs

**GitHub**
-
Ap√≥s feito o Fork, acesse as configura√ß√µes do reposit√≥rio em: **Settings > Secrets and variables > Actions** para que possamos criar nossas Secrets.
- Criaremos sete secrets ao todo, seram elas:
    - AWS_ACCESS_KEY_APP -> Recebera a Acess Key do usu√°rio que criamos para nossa aplica√ß√£o.
    - AWS_SECRET_ACCESS_KEY_APP -> Recebera a Secret Key do usu√°rio que criamos para nossa aplica√ß√£o.
    - AWS_ACCESS_KEY_CI_CD -> Recebera a Acess Key do usu√°rio que criamos para o Terraform.
    - AWS_SECRET_ACCESS_KEY_CI_CD -> Recebera a Secret Key do usu√°rio que criamos para o Terraform.
    - RS_BUCKET_NAME -> Recebera o nome do bucket que criamos para armazenar o Remote State do Terraform
    - RS_KEY_PATH_FILE -> Receber√° o caminho seguido do nome do arquivo de state que ser√° criado pelo Terraform. Ex: aws_infra/terraform.tfstate
    - RS_REGION -> Receber√° a regi√£o da AWS onde o bucket foi criado
Detalhados os conte√∫dos cada secret deve conter, basta cria-las nas configura√ß√µes do seu reposit√≥rio GitHub

**Terraform**
-
Caso queira personalisar as configura√ß√µes de infraestrutura , basta fazer as altera√ß√µes no seguinte arquivo **./terraform/variables.tf**. Todas os par√¢metros de configura√ß√µes da nossa Stack Terraform se encontram no mesmo. Recomendo que voc√™ d√™ uma aten√ß√£o especial a este arquivo e suas configura√ß√µes antes de realizar o deploy, para que tome conhecimento de todos os recursos que ser√£o provisionados e possa fazer sua estimativa de custos afim de estar ciente de todos custos que ser√£o gerados por parte do Cloud Provider.

**Executando a Pipeline de Deploy**
-
Agora vamos Finalmente fazer o deploy de toda nossa Stack na AWS. Para isso acesse a Actions do seu reposit√≥rio e execute o seguinte Workflow: **Deploy Full - Infrastructure and Application** clicando em **Run Workflow**.

**Executando a Pipeline de Destroy**
-
Quando n√£o for mais utilizar a aplica√ß√£o, n√£o se esque√ßa de excluir os recusros criados na AWS a fim de evitar cobran√ßas indesejadas. Para isso acesse a Actions do seu reposit√≥rio e execute o seguinte Workflow: **Workflow Destroy Infrastructure** clicando em **Run Workflow**.

## ü§ì  Conhecendo a aplica√ß√£o

Nossa aplica√ß√£o consiste em uma api que que se comunica com o servi√ßo AWS EC2 e interagem com as instancias ali provisionadas por meio de requisi√ß√µes HTTP. Vamos conhecer mais de suas funcionalidades e como utiliza-las.

## üìë Documenta√ß√£o da API

#### Retorna todas as Instancias EC2

```bash
  GET /ec2_list
```

| Par√¢metro       | Tipo       | Descri√ß√£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **Obrigat√≥rio**. Regi√£o AWS que deseja interagir    |

#### Desliga uma instancia EC2

```bash
  POST /ec2_stop
```

| Par√¢metro       | Tipo       | Descri√ß√£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **Obrigat√≥rio**. Regi√£o AWS que deseja interagir    |
| `instance_id`   | `string`   | **Obrigat√≥rio**. Id da Instacia que deseja desligar |

#### Liga uma instancia EC2

```bash
  POST /ec2_start
```

| Par√¢metro       | Tipo       | Descri√ß√£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **Obrigat√≥rio**. Regi√£o AWS que deseja interagir    |
| `instance_id`   | `string`   | **Obrigat√≥rio**. Id da Instacia que deseja ligar    |

#### Reinicia uma instancia EC2

```bash
  POST /ec2_reboot
```

| Par√¢metro       | Tipo       | Descri√ß√£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **Obrigat√≥rio**. Regi√£o AWS que deseja interagir    |
| `instance_id`   | `string`   | **Obrigat√≥rio**. Id da Instacia que deseja reiniciar|

#### Modifica o tipo da instancia EC2

```bash
  POST /ec2_instance_type_modify
```

| Par√¢metro       | Tipo       | Descri√ß√£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **Obrigat√≥rio**. Regi√£o AWS que deseja interagir    |
| `instance_id`   | `string`   | **Obrigat√≥rio**. Id da Instacia que deseja reiniciar|
| `instance_type` | `string`   | **Obrigat√≥rio**. Novo tipo de instancia desejado    |

## ‚öôÔ∏è Terraform

Toda a infraestrutura do projeto foi desenvolvida de forma declarativa atrav√©s do Terraform para assim podermos usufruir de alguns dos benef√≠cios do IaC, como versionamento, automa√ß√£o, performance, idempotencia, ...

Para a infraestrutura da nossa aplica√ß√£o utlizamos uma s√©rie de recursos como: VPC, Internet Gateway, Nat Gateway, Security Groups, ECS, ALB, dentre outros. Para uma melhor entendimento segue um esbo√ßo da nossa arquitetura:

<img src="https://i.imgur.com/8GUf5UV.png" width="720" height="800">

Na arquitetura acima contamos com:
- 1 VPC
- 2 Subnets Publicas e 2 Subnets privadas
- 1 internet Gateway
- 2 Nat Gateways
- 1 Routatable publica com sa√≠ da para o Internet Gateway
- 2 Route tables privadas com sa√≠da para os 2 Nat Gateways
- 1 Taget Group associado √†s duas Subnets privadas
- 1 Cluster ECS Fargate que provisionar√° os containers da nossa aplica√ß√£o nas duas zonas privada
- 1 Application Load Balancer associado as 2 Subnets publicas, recebendo e enviando o trafego recebido para os containers associados ao Target Group.

No cod√≠go Terraform foi aplicado o conceito de m√≥dulos re√∫tilizaveis. Tornando nosso codigo, como o proprio nome ja diz,  reutiliz√°vel e de f√°cil personaliza√ß√£o, visto que cada recurso desejado √© referenciado no arquivo **main.tf** e todos as informa√ß√µes e par√¢metros que devem ser fornecidas pelo usu√°rio ficam concentradas em um unico arquivo chamado **variables.tf**.

Caso queira entender a estrutura e organiza√ß√£o dos templates Terraform, segue a estrutura:

```bash
.
‚îú‚îÄ‚îÄ main.tf
‚îú‚îÄ‚îÄ modules
‚îÇ   ‚îú‚îÄ‚îÄ alb_module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alb.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ locals.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ variables.tf
‚îÇ   ‚îú‚îÄ‚îÄ ecr_module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ecr.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ locals.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ variables.tf
‚îÇ   ‚îú‚îÄ‚îÄ ecs_module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auto_scale.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ecs.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ iam.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ locals.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ target-group.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ variables.tf
‚îÇ   ‚îú‚îÄ‚îÄ security_groups_module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ locals.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security-groups.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ variables.tf
‚îÇ   ‚îî‚îÄ‚îÄ vpc_module
‚îÇ       ‚îú‚îÄ‚îÄ locals.tf
‚îÇ       ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ       ‚îú‚îÄ‚îÄ variables.tf
‚îÇ       ‚îî‚îÄ‚îÄ vpc.tf
‚îú‚îÄ‚îÄ outputs.tf
‚îú‚îÄ‚îÄ template
‚îÇ   ‚îî‚îÄ‚îÄ app.json.tpl
‚îú‚îÄ‚îÄ terraform.tfstate
‚îú‚îÄ‚îÄ terraform.tfstate.backup
‚îî‚îÄ‚îÄ variables.tf
```

## üèó GitHub Actions

Para a automa√ß√£o do nosso processo de Deploy tanto da Infraestrutura quanto da aplica√ß√£o utilizamos o GitHub Actions. Atrav√©s de seus Workflows de Integra√ß√£o e Entrega Cont√≠nua foi possivel integrar elementos chaves entre os dois procedimentos de deploy. Visto que para fazer o deploy da aplica√ß√£o necessitamos que primeiro sejam criado os componentes de infraestrutura. 

Dessa forma o nosso primeiro workflow em quest√£o. Declarado no arquivo **.github/workflows/workflow_complete.yml**. Cria toda a nossa infraestrutura na AWS e exporta como vari√°vel de ambiente informa√ß√µes importantes para o deploy da aplica√ß√£o como: a url do reposit√≥rio ECR para que bossamos fazer o push da imagem docker ap√≥s o processo de build, os nomes do cluster ECS e do service para que possamos enviar a ordem de novo deploy ao Cluster ECS.

Assim o Job que faz o build da aplica√ß√£o consegue herdar do Job do Terraform as informa√ß√µes que precisa para pazer o Deploy da aplica√ß√£o no Cluster ECS.

O nosso segundo workflow declarado no arquivo **.github/workflows/workflow_validate_and_plan_code.yml** tem como objetivo Validar a intregridade do codigo terraform a cada novo commit enviado ao repos√≠t√≥rio. Dessa forma pode-se ver se o codigo Terraform n√£o possui nenhum erro de syntax e podemos conferir todos os recurso que ser√£o ou n√£o criados em caso de execu√ß√£o do Workflow que faz o Deploy completo da Stack.

Por fim mas n√£o menos importante temos o nosso Workflow de destroy, declarado no arquvo **.github/workflows/workflow_destroy.yml**. Que como o proprio nome sugere, ao ser executado, destroi todos os recursos provisionados na Cloud da AWS.

Dessa forma podemos, al√©m de validar nosso c√≥digo a cada commit enviado e conferir quais recurso de infraestrutura ser√£o criados antes de excutar o Workflow de deploy. Ter a possibilidade de criar e destruir toda a nossa Stack com um clique.
