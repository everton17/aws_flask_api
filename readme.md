
# AWS EC2 Manage Instances API

Este projeto foi desenvolvido como objeto de estudos e aplicaÃ§Ã£o de uma sÃ©rie de conhecimentos, tecnologias e habilidades voltados para o ecossistema DevOps. Trabalhando alguns tÃ³picos como: ProgramÃ§Ã£o, Cloud, IaC, Containers e CI/CD.

O core do projeto se trata de uma aplicaÃ§Ã£o que possibilita interaÃ§Ãµes simples com serviÃ§o AWS EC2 via requisiÃ§Ãµes HTTP, como por exemplo Listar instancias e realizar algumas aÃ§Ãµes com as mesmas como: ligar, desligar, reiniciar e modificar a classe das instancias.


## ğŸ›  Stack utilizada

**AplicaÃ§Ã£o:** Python, Flask, Flask-Restful, Boto3, Gunicorn

**Infraestrutura:** AWS, Terraform, Docker, ECS (Elastic Container Service)

**CI/CD:** GitHub Actions 


## âœ… API - PrÃ© requisitos

Para utilizaÃ§Ã£o da aplicaÃ§Ã£o precisaremos de alguns itens instados no nosso ambiente:

- Uma conta AWS, usuÃ¡rio e credenciais com permissÃ§Ãµees ao serviÃ§o EC2
- Python 3.10
- AWS Cli


## ğŸ”— Links

Segue abaixo alguns links que pode ajudar na configuraÃ§Ã£o do ambiente

[InstalaÃ§Ã£o do Python e AWS Cli no Windows](https://docs.aws.amazon.com/pt_br/elasticbeanstalk/latest/dg/eb-cli3-install-windows.html)

[InstalaÃ§Ã£o do Python e AWS Cli no Linux](https://docs.aws.amazon.com/pt_br/elasticbeanstalk/latest/dg/eb-cli3-install-linux.html)

[Criando um usÃ¡rio AWS no console AWS](https://docs.aws.amazon.com/pt_br/IAM/latest/UserGuide/id_users_create.html#id_users_create_console)

[Configurando credenciais de usuÃ¡rio no AWS Cli](https://docs.aws.amazon.com/pt_br/cli/latest/userguide/cli-configure-files.html)


## ğŸ  Executando localmente

ApÃ³s a configuraÃ§Ã£o do ambiente e das credenciais de usuÃ¡rio junto aos AWS Cli basta seguir os passos abaixo:

**Obs: Para usuÃ¡rios windows recomendado utilizar o WSL2**

Clone o projeto

```bash
  git clone https://github.com/everton17/aws_flask_api.git
```

Entre no diretÃ³rio do projeto

```bash
  cd aws_flask_api
```

Crie uma virtual-env

```bash
  python3 -m venv .venv
```

Ative a Virtual-env

```bash
  source .venv/bin/activate
```

Instale as bibliotecas do projeto

```bash
  pip install -r requirements.txt
```

Execute a aplicaÃ§Ã£o

```bash
  gunicorn --bind 0.0.0.0:5000 -w 4 run:app
```

## ğŸ³ Executando localmente com Docker

ApÃ³s a configuraÃ§Ã£o do ambiente e das credenciais de usuÃ¡rio junto aos AWS Cli basta seguir os passos abaixo:

**Obs: para esta execuÃ§Ã£o vocÃª necessariamente do docker intalado na sua maquina**

[InstalaÃ§Ã£o do Docker](https://docs.docker.com/get-docker/)


Clone o projeto

```bash
  git clone https://github.com/everton17/aws_flask_api.git
```

Entre no diretÃ³rio do projeto

```bash
  cd aws_flask_api
```

Entre no diretÃ³rio do projeto

```bash
  cd aws_flask_api
```

Execute o docker build referenciando as credenciais AWS como build-args

```bash
  docker build -t aws_ec2_flask_api . --build-arg ACCESS_KEY=<AWS_ACCESS_KEY> --build-arg SECRET_KEY=<AWS_SECRET_ACCESS_KEY>
```

Agora vamos executar o container da nossa aplicaÃ§Ã£o

```bash
  docker run -d --name aws-api -p 127.0.0.1:5000:5000 aws_ec2_flask_api:latest
```

## â˜ï¸ Executando na Cloud AWS

Para execuÃ§Ã£o da nossa aplicaÃ§Ã£o na AWS o projeto contempla uma Stack Terraform, onde faremos o deploy atravÃ©s de uma pipeline CI/CD utilizando o GitHub Actions

**Obs: para esta execuÃ§Ã£o vocÃª precisarÃ¡ fazer um fork do projeto e algumas configuraÃ§Ãµes no seu GitHub e na sua conta AWS**

Para que possamos deployar nossa stack terraform na AWS precisaremos cumprir alguns prÃ© requisitos:

**AWS**
-
- Criar um Bucket S3 para armazenar nosso Terraform Remote State
- Criar um novo usuÃ¡rio na AWS com permissÃµes para criar e destruir recursos dos seguintes serviÃ§os:
    - EC2
    - ECR
    - ECS
    - VPC
    - Cloud Watch Logs

**GitHub**
-
ApÃ³s feito o Fork, acesse as configuraÃ§Ãµes do repositÃ³rio em: **Settings > Secrets and variables > Actions** para que possamos criar nossas Secrets.
- Criaremos sete secrets ao todo, seram elas:
    - AWS_ACCESS_KEY_APP -> Recebera a Acess Key do usuÃ¡rio que criamos para nossa aplicaÃ§Ã£o.
    - AWS_SECRET_ACCESS_KEY_APP -> Recebera a Secret Key do usuÃ¡rio que criamos para nossa aplicaÃ§Ã£o.
    - AWS_ACCESS_KEY_CI_CD -> Recebera a Acess Key do usuÃ¡rio que criamos para o Terraform.
    - AWS_SECRET_ACCESS_KEY_CI_CD -> Recebera a Secret Key do usuÃ¡rio que criamos para o Terraform.
    - RS_BUCKET_NAME -> Recebera o nome do bucket que criamos para armazenar o Remote State do Terraform
    - RS_KEY_PATH_FILE -> ReceberÃ¡ o caminho seguido do nome do arquivo de state que serÃ¡ criado pelo Terraform. Ex: aws_infra/terraform.tfstate
    - RS_REGION -> ReceberÃ¡ a regiÃ£o da AWS onde o bucket foi criado
Detalhados os conteÃºdos cada secret deve conter, basta cria-las nas configuraÃ§Ãµes do seu repositÃ³rio GitHub

**Terraform**
-
Caso queira personalisar as configuraÃ§Ãµes de infraestrutura , basta fazer as alteraÃ§Ãµes no seguinte arquivo **./terraform/variables.tf**. Todas os parÃ¢metros de configuraÃ§Ãµes da nossa Stack Terraform se encontram no mesmo. Recomendo que vocÃª dÃª uma atenÃ§Ã£o especial a este arquivo e suas configuraÃ§Ãµes antes de realizar o deploy, para que tome conhecimento de todos os recursos que serÃ£o provisionados e possa fazer sua estimativa de custos afim de estar ciente de todos custos que serÃ£o gerados por parte do Cloud Provider.

**Executando a Pipeline de Deploy**
-
Agora vamos Finalmente fazer o deploy de toda nossa Stack na AWS. Para isso acesse a Actions do seu repositÃ³rio e execute o seguinte Workflow: **Deploy Full - Infrastructure and Application** clicando em **Run Workflow**.

**Executando a Pipeline de Destroy**
-
Quando nÃ£o for mais utilizar a aplicaÃ§Ã£o, nÃ£o se esqueÃ§a de excluir os recusros criados na AWS a fim de evitar cobranÃ§as indesejadas. Para isso acesse a Actions do seu repositÃ³rio e execute o seguinte Workflow: **Workflow Destroy Infrastructure** clicando em **Run Workflow**.

## ğŸ¤“  Conhecendo a aplicaÃ§Ã£o

Nossa aplicaÃ§Ã£o consiste em uma api que que se comunica com o serviÃ§o AWS EC2 e interagem com as instancias ali provisionadas por meio de requisiÃ§Ãµes HTTP. Vamos conhecer mais de suas funcionalidades e como utiliza-las.

## ğŸ“‘ DocumentaÃ§Ã£o da API

#### Retorna todas as Instancias EC2

```bash
  GET /ec2_list
```

| ParÃ¢metro       | Tipo       | DescriÃ§Ã£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **ObrigatÃ³rio**. RegiÃ£o AWS que deseja interagir    |

#### Desliga uma instancia EC2

```bash
  POST /ec2_stop
```

| ParÃ¢metro       | Tipo       | DescriÃ§Ã£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **ObrigatÃ³rio**. RegiÃ£o AWS que deseja interagir    |
| `instance_id`   | `string`   | **ObrigatÃ³rio**. Id da Instacia que deseja desligar |

#### Liga uma instancia EC2

```bash
  POST /ec2_start
```

| ParÃ¢metro       | Tipo       | DescriÃ§Ã£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **ObrigatÃ³rio**. RegiÃ£o AWS que deseja interagir    |
| `instance_id`   | `string`   | **ObrigatÃ³rio**. Id da Instacia que deseja ligar    |

#### Reinicia uma instancia EC2

```bash
  POST /ec2_reboot
```

| ParÃ¢metro       | Tipo       | DescriÃ§Ã£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **ObrigatÃ³rio**. RegiÃ£o AWS que deseja interagir    |
| `instance_id`   | `string`   | **ObrigatÃ³rio**. Id da Instacia que deseja reiniciar|

#### Modifica o tipo da instancia EC2

```bash
  POST /ec2_instance_type_modify
```

| ParÃ¢metro       | Tipo       | DescriÃ§Ã£o                                           |
| :----------     | :--------- | :---------------------------------------------------|
| `region`        | `string`   | **ObrigatÃ³rio**. RegiÃ£o AWS que deseja interagir    |
| `instance_id`   | `string`   | **ObrigatÃ³rio**. Id da Instacia que deseja reiniciar|
| `instance_type` | `string`   | **ObrigatÃ³rio**. Novo tipo de instancia desejado    |

## âš™ï¸ Terraform

Toda a infraestrutura do projeto foi desenvolvida de forma declarativa atravÃ©s do Terraform para assim podermos usufruir de alguns dos benefÃ­cios do IaC, como versionamento, automaÃ§Ã£o, performance, idempotencia, ...

Para a infraestrutura da nossa aplicaÃ§Ã£o utlizamos uma sÃ©rie de recursos como: VPC, Internet Gateway, Nat Gateway, Security Groups, ECS, ALB, dentre outros. Para uma melhor entendimento segue um esboÃ§o da nossa arquitetura:

<img src="https://i.imgur.com/8GUf5UV.png" width="720" height="800">

Na arquitetura acima contamos com:
- 1 VPC
- 2 Subnets Publicas e 2 Subnets privadas
- 1 internet Gateway
- 2 Nat Gateways
- 1 Routatable publica com saÃ­ da para o Internet Gateway
- 2 Route tables privadas com saÃ­da para os 2 Nat Gateways
- 1 Taget Group associado Ã s duas Subnets privadas
- 1 Cluster ECS Fargate que provisionarÃ¡ os containers da nossa aplicaÃ§Ã£o nas duas zonas privada
- 1 Application Load Balancer associado as 2 Subnets publicas, recebendo e enviando o trafego recebido para os containers associados ao Target Group.

No codÃ­go Terraform foi aplicado o conceito de mÃ³dulos reÃºtilizaveis. Tornando nosso codigo, como o proprio nome ja diz,  reutilizÃ¡vel e de fÃ¡cil personalizaÃ§Ã£o, visto que cada recurso desejado Ã© referenciado no arquivo **main.tf** e todos as informaÃ§Ãµes e parÃ¢metros que devem ser fornecidas pelo usuÃ¡rio ficam concentradas em um unico arquivo chamado **variables.tf**.

Caso queira entender a estrutura e organizaÃ§Ã£o dos templates Terraform, segue a estrutura:

```bash
.
â”œâ”€â”€ main.tf
â”œâ”€â”€ modules
â”‚   â”œâ”€â”€ alb_module
â”‚   â”‚   â”œâ”€â”€ alb.tf
â”‚   â”‚   â”œâ”€â”€ locals.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â””â”€â”€ variables.tf
â”‚   â”œâ”€â”€ ecr_module
â”‚   â”‚   â”œâ”€â”€ ecr.tf
â”‚   â”‚   â”œâ”€â”€ locals.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â””â”€â”€ variables.tf
â”‚   â”œâ”€â”€ ecs_module
â”‚   â”‚   â”œâ”€â”€ auto_scale.tf
â”‚   â”‚   â”œâ”€â”€ ecs.tf
â”‚   â”‚   â”œâ”€â”€ iam.tf
â”‚   â”‚   â”œâ”€â”€ locals.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ target-group.tf
â”‚   â”‚   â””â”€â”€ variables.tf
â”‚   â”œâ”€â”€ security_groups_module
â”‚   â”‚   â”œâ”€â”€ locals.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ security-groups.tf
â”‚   â”‚   â””â”€â”€ variables.tf
â”‚   â””â”€â”€ vpc_module
â”‚       â”œâ”€â”€ locals.tf
â”‚       â”œâ”€â”€ outputs.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â””â”€â”€ vpc.tf
â”œâ”€â”€ outputs.tf
â”œâ”€â”€ template
â”‚   â””â”€â”€ app.json.tpl
â”œâ”€â”€ terraform.tfstate
â”œâ”€â”€ terraform.tfstate.backup
â””â”€â”€ variables.tf
```

## ğŸ— GitHub Actions

Para a automaÃ§Ã£o do nosso processo de Deploy tanto da Infraestrutura quanto da aplicaÃ§Ã£o utilizamos o GitHub Actions. AtravÃ©s de seus Workflows de IntegraÃ§Ã£o e Entrega ContÃ­nua foi possivel integrar elementos chaves entre os dois procedimentos de deploy. Visto que para fazer o deploy da aplicaÃ§Ã£o necessitamos que primeiro sejam criado os componentes de infraestrutura. 

Dessa forma o nosso primeiro workflow em questÃ£o. Declarado no arquivo **.github/workflows/workflow_complete.yml**. Cria toda a nossa infraestrutura na AWS e exporta como variÃ¡vel de ambiente informaÃ§Ãµes importantes para o deploy da aplicaÃ§Ã£o como: a url do repositÃ³rio ECR para que bossamos fazer o push da imagem docker apÃ³s o processo de build, os nomes do cluster ECS e do service para que possamos enviar a ordem de novo deploy ao Cluster ECS.

Assim o Job que faz o build da aplicaÃ§Ã£o consegue herdar do Job do Terraform as informaÃ§Ãµes que precisa para pazer o Deploy da aplicaÃ§Ã£o no Cluster ECS.

O nosso segundo workflow declarado no arquivo **.github/workflows/workflow_validate_and_plan_code.yml** tem como objetivo Validar a intregridade do codigo terraform a cada novo commit enviado ao reposÃ­tÃ³rio. Dessa forma pode-se ver se o codigo Terraform nÃ£o possui nenhum erro de syntax e podemos conferir todos os recurso que serÃ£o ou nÃ£o criados em caso de execuÃ§Ã£o do Workflow que faz o Deploy completo da Stack.

Por fim mas nÃ£o menos importante temos o nosso Workflow de destroy, declarado no arquvo **.github/workflows/workflow_destroy.yml**. Que como o proprio nome sugere, ao ser executado, destroi todos os recursos provisionados na Cloud da AWS.

Dessa forma podemos, alÃ©m de validar nosso cÃ³digo a cada commit enviado e conferir quais recurso de infraestrutura serÃ£o criados antes de excutar o Workflow de deploy. Ter a possibilidade de criar e destruir toda a nossa Stack com um clique.
